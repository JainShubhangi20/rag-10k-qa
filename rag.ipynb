{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "# %pip install pymupdf sentence-transformers faiss-cpu chromadb transformers torch accelerate pdfplumber -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded files:\n",
            "  10-Q4-2024-As-Filed.pdf (0.9 MB)\n",
            "  tsla-20231231-gen.pdf (0.9 MB)\n"
          ]
        }
      ],
      "source": [
        "# Download PDFs\n",
        "!wget -q \"https://s2.q4cdn.com/470004039/files/doc_earnings/2024/q4/filing/10-Q4-2024-As-Filed.pdf\" -O /content/10-Q4-2024-As-Filed.pdf\n",
        "!wget -q \"https://ir.tesla.com/_flysystem/s3/sec/000162828024002390/tsla-20231231-gen.pdf\" -O /content/tsla-20231231-gen.pdf\n",
        "\n",
        "import os\n",
        "print(\"Downloaded files:\")\n",
        "for f in [\"10-Q4-2024-As-Filed.pdf\", \"tsla-20231231-gen.pdf\"]:\n",
        "    path = f\"/content/{f}\"\n",
        "    if os.path.exists(path):\n",
        "        size = os.path.getsize(path) / (1024*1024)\n",
        "        print(f\"  {f} ({size:.1f} MB)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports and config\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import pdfplumber\n",
        "import faiss\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "DATA_DIR = \"/content\"\n",
        "APPLE_PDF = os.path.join(DATA_DIR, \"10-Q4-2024-As-Filed.pdf\")\n",
        "TESLA_PDF = os.path.join(DATA_DIR, \"tsla-20231231-gen.pdf\")\n",
        "\n",
        "EMBEDDING_MODEL = \"BAAI/bge-small-en-v1.5\"\n",
        "RERANKER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "LLM_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chunk data structure\n",
        "@dataclass\n",
        "class Chunk:\n",
        "    text: str\n",
        "    doc_name: str\n",
        "    page: int\n",
        "    section: Optional[str] = None\n",
        "    chunk_id: int = 0\n",
        "    \n",
        "    def citation(self):\n",
        "        parts = [self.doc_name]\n",
        "        if self.section:\n",
        "            parts.append(self.section)\n",
        "        parts.append(f\"p. {self.page}\")\n",
        "        return str(parts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Section detection patterns\n",
        "SECTION_PATTERNS = [\n",
        "    (r\"(?i)\\bITEM\\s*1[A-B]?\\b\", \"Item 1\"), (r\"(?i)\\bITEM\\s*1A\\b\", \"Item 1A\"),\n",
        "    (r\"(?i)\\bITEM\\s*1B\\b\", \"Item 1B\"), (r\"(?i)\\bITEM\\s*1C\\b\", \"Item 1C\"),\n",
        "    (r\"(?i)\\bITEM\\s*2\\b\", \"Item 2\"), (r\"(?i)\\bITEM\\s*3\\b\", \"Item 3\"),\n",
        "    (r\"(?i)\\bITEM\\s*4\\b\", \"Item 4\"), (r\"(?i)\\bITEM\\s*5\\b\", \"Item 5\"),\n",
        "    (r\"(?i)\\bITEM\\s*6\\b\", \"Item 6\"), (r\"(?i)\\bITEM\\s*7[A]?\\b\", \"Item 7\"),\n",
        "    (r\"(?i)\\bITEM\\s*7A\\b\", \"Item 7A\"), (r\"(?i)\\bITEM\\s*8\\b\", \"Item 8\"),\n",
        "    (r\"(?i)\\bITEM\\s*9[A-C]?\\b\", \"Item 9\"), (r\"(?i)\\bITEM\\s*10\\b\", \"Item 10\"),\n",
        "    (r\"(?i)\\bITEM\\s*11\\b\", \"Item 11\"), (r\"(?i)\\bITEM\\s*12\\b\", \"Item 12\"),\n",
        "    (r\"(?i)\\bITEM\\s*13\\b\", \"Item 13\"), (r\"(?i)\\bITEM\\s*14\\b\", \"Item 14\"),\n",
        "    (r\"(?i)\\bITEM\\s*15\\b\", \"Item 15\"), (r\"(?i)\\bITEM\\s*16\\b\", \"Item 16\"),\n",
        "]\n",
        "\n",
        "def detect_section(text):\n",
        "    header = text[:500]\n",
        "    for pattern, name in SECTION_PATTERNS:\n",
        "        if re.search(pattern, header):\n",
        "            return name\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PDF parsing functions\n",
        "def format_table(table):\n",
        "    if not table or len(table) < 2:\n",
        "        return \"\"\n",
        "    headers = [str(h).strip() if h else \"\" for h in (table[0] or [])]\n",
        "    rows = []\n",
        "    for row in table[1:]:\n",
        "        if not row:\n",
        "            continue\n",
        "        parts = []\n",
        "        for i, cell in enumerate(row):\n",
        "            val = str(cell).strip() if cell else \"\"\n",
        "            if val:\n",
        "                if i < len(headers) and headers[i]:\n",
        "                    parts.append(f\"{headers[i]}: {val}\")\n",
        "                else:\n",
        "                    parts.append(val)\n",
        "        if parts:\n",
        "            rows.append(\" | \".join(parts))\n",
        "    return \"\\n\".join(rows)\n",
        "\n",
        "def parse_pdf(pdf_path, doc_name):\n",
        "    pages = []\n",
        "    current_section = None\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for i, page in enumerate(pdf.pages):\n",
        "            text = page.extract_text() or \"\"\n",
        "            tables = page.extract_tables()\n",
        "            if tables:\n",
        "                table_text = \"\\n\\n\".join(format_table(t) for t in tables if t)\n",
        "                text = text + \"\\n\\n\" + table_text\n",
        "            text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
        "            text = re.sub(r' {2,}', ' ', text).strip()\n",
        "            section = detect_section(text)\n",
        "            if section:\n",
        "                current_section = section\n",
        "            pages.append({\"text\": text, \"page\": i + 1, \"section\": current_section})\n",
        "    return pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text chunking\n",
        "def split_text(text, chunk_size=1000, overlap=200):\n",
        "    if len(text) <= chunk_size:\n",
        "        return [text] if text.strip() else []\n",
        "    \n",
        "    for sep in [\"\\n\\n\", \"\\n\", \". \", \" \"]:\n",
        "        if sep in text:\n",
        "            break\n",
        "    else:\n",
        "        sep = \"\"\n",
        "    \n",
        "    parts = text.split(sep) if sep else list(text)\n",
        "    chunks = []\n",
        "    current = []\n",
        "    current_len = 0\n",
        "    \n",
        "    for part in parts:\n",
        "        part_len = len(part) + len(sep)\n",
        "        if current_len + part_len > chunk_size and current:\n",
        "            chunks.append(sep.join(current))\n",
        "            overlap_text = sep.join(current)\n",
        "            if len(overlap_text) > overlap:\n",
        "                overlap_text = overlap_text[-overlap:]\n",
        "                dot = overlap_text.find(\". \")\n",
        "                if dot != -1 and dot < len(overlap_text) - 10:\n",
        "                    overlap_text = overlap_text[dot + 2:]\n",
        "            current = [overlap_text] if overlap_text else []\n",
        "            current_len = len(overlap_text)\n",
        "        current.append(part)\n",
        "        current_len += part_len\n",
        "    \n",
        "    if current:\n",
        "        chunks.append(sep.join(current))\n",
        "    return chunks\n",
        "\n",
        "def chunk_document(pages, doc_name, chunk_size=1000, overlap=200):\n",
        "    chunks = []\n",
        "    chunk_id = 0\n",
        "    for page in pages:\n",
        "        for text in split_text(page[\"text\"], chunk_size, overlap):\n",
        "            if text.strip():\n",
        "                chunks.append(Chunk(text=text, doc_name=doc_name, page=page[\"page\"], section=page[\"section\"], chunk_id=chunk_id))\n",
        "                chunk_id += 1\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing Apple 10-K...\n",
            "  -> 496 chunks\n",
            "Parsing Tesla 10-K...\n",
            "  -> 521 chunks\n",
            "\n",
            "Total: 1017 chunks\n"
          ]
        }
      ],
      "source": [
        "# Load and chunk both PDFs\n",
        "print(\"Parsing Apple 10-K...\")\n",
        "apple_pages = parse_pdf(APPLE_PDF, \"Apple 10-K\")\n",
        "apple_chunks = chunk_document(apple_pages, \"Apple 10-K\")\n",
        "print(f\"  -> {len(apple_chunks)} chunks\")\n",
        "\n",
        "print(\"Parsing Tesla 10-K...\")\n",
        "tesla_pages = parse_pdf(TESLA_PDF, \"Tesla 10-K\")\n",
        "tesla_chunks = chunk_document(tesla_pages, \"Tesla 10-K\")\n",
        "print(f\"  -> {len(tesla_chunks)} chunks\")\n",
        "\n",
        "all_chunks = apple_chunks + tesla_chunks\n",
        "for i, chunk in enumerate(all_chunks):\n",
        "    chunk.chunk_id = i\n",
        "print(f\"\\nTotal: {len(all_chunks)} chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vector store\n",
        "class VectorStore:\n",
        "    def __init__(self, embed_model):\n",
        "        self.embed_model = embed_model\n",
        "        self.dim = embed_model.get_sentence_embedding_dimension()\n",
        "        self.index = faiss.IndexFlatIP(self.dim)\n",
        "        self.chunks = []\n",
        "    \n",
        "    def add(self, chunks, batch_size=32):\n",
        "        print(f\"Embedding {len(chunks)} chunks...\")\n",
        "        texts = [c.text for c in chunks]\n",
        "        embeddings = self.embed_model.encode(texts, batch_size=batch_size, show_progress_bar=True, normalize_embeddings=True)\n",
        "        embeddings = np.array(embeddings).astype('float32')\n",
        "        self.index.add(embeddings)\n",
        "        self.chunks.extend(chunks)\n",
        "        print(f\"  -> Done! Total: {len(self.chunks)} chunks\")\n",
        "    \n",
        "    def search(self, query, k=5):\n",
        "        q_embed = self.embed_model.encode([query], normalize_embeddings=True).astype('float32')\n",
        "        scores, indices = self.index.search(q_embed, k)\n",
        "        results = []\n",
        "        for idx, score in zip(indices[0], scores[0]):\n",
        "            if idx < len(self.chunks):\n",
        "                results.append((self.chunks[idx], float(score)))\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retriever with re-ranking\n",
        "class Retriever:\n",
        "    def __init__(self, store, reranker_model=None):\n",
        "        self.store = store\n",
        "        self.reranker = None\n",
        "        if reranker_model:\n",
        "            print(f\"Loading re-ranker: {reranker_model}\")\n",
        "            self.reranker = CrossEncoder(reranker_model)\n",
        "    \n",
        "    def retrieve(self, query, top_k=5, initial_k=20):\n",
        "        candidates = self.store.search(query, k=initial_k if self.reranker else top_k)\n",
        "        if self.reranker and candidates:\n",
        "            pairs = [(query, c.text) for c, _ in candidates]\n",
        "            scores = self.reranker.predict(pairs)\n",
        "            reranked = [(candidates[i][0], float(scores[i])) for i in range(len(candidates))]\n",
        "            reranked.sort(key=lambda x: x[1], reverse=True)\n",
        "            return reranked[:top_k]\n",
        "        return candidates\n",
        "    \n",
        "    def get_context(self, query, top_k=5):\n",
        "        results = self.retrieve(query, top_k=top_k)\n",
        "        if not results:\n",
        "            return \"\", [], []\n",
        "        context_parts = []\n",
        "        sources = []\n",
        "        chunks = []\n",
        "        for chunk, score in results:\n",
        "            src = f\"[Source: {chunk.doc_name}\"\n",
        "            if chunk.section:\n",
        "                src += f\", {chunk.section}\"\n",
        "            src += f\", p. {chunk.page}]\"\n",
        "            context_parts.append(f\"{src}\\n{chunk.text}\")\n",
        "            sources.append(chunk.citation())\n",
        "            chunks.append(chunk)\n",
        "        return \"\\n\\n---\\n\\n\".join(context_parts), sources, chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embedding model: BAAI/bge-small-en-v1.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6569cc91aee4cc9aa530c22888863a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a388439955ed41a7810b4e62106e3ad1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b3c496c801640718fe90860dcf6966f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33a0cf8b025a44febd30b003e9894290",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aa44ea556ad481fac2687e4e2f7302e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bca1e181dbbc4516a583480aae34bbde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "610f24e6519b4eb4800891516a136584",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fbdc0eda6604f59ac0468baa908ae2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a4666b785e54452987b708d8b0a3998",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc070b5814be4303a2002d1717d929ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e18828fdc224e18a57fdd3d0f014b8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding 1017 chunks...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db8d5b99977b48cd97570cd1df4b70ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  -> Done! Total: 1017 chunks\n",
            "Loading re-ranker: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8ddaf96411c4bf49be4eabf97bec66b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0911bfae634470595d16a396c4cd374",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "614b3eb926f944b2803debdb30592f89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a33a3b2ce4004577affebdb5a1b1afa6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9c8395811c94feab221582cf955fe44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58e176ac719949d988fa8ae39880fbb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1526ea1f156a42308fe8309a5b38efee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build vector store and retriever\n",
        "print(f\"Loading embedding model: {EMBEDDING_MODEL}\")\n",
        "embed_model = SentenceTransformer(EMBEDDING_MODEL)\n",
        "\n",
        "store = VectorStore(embed_model)\n",
        "store.add(all_chunks)\n",
        "\n",
        "retriever = Retriever(store, RERANKER_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading LLM on cuda...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e31f8cd36d8d4769ae22184f81d89bc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fc79fd1d0f244e4b9e85f1471539d67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0be8d079c3b542778cc37eaf55c03e68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12d359c957794e8fbaef4b931508600a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b57b78f2cef4d07a32c9d595039b999",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b671ad187bf44cf4895091d4bc0d4753",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c15e88f7929347f18df07a1067f67e57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Load LLM\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Loading LLM on {device}...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL)\n",
        "model = AutoModelForCausalLM.from_pretrained(LLM_MODEL, torch_dtype=torch.float32, low_cpu_mem_usage=True).to(device)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generation function\n",
        "def generate(prompt, max_tokens=200):\n",
        "    max_input = 2048 - max_tokens - 50\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_input).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_new_tokens=max_tokens, do_sample=False, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)\n",
        "    input_len = inputs[\"input_ids\"].shape[1]\n",
        "    generated = outputs[0][input_len:]\n",
        "    return tokenizer.decode(generated, skip_special_tokens=True).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prompt template and helpers\n",
        "PROMPT_TEMPLATE = \"\"\"<|system|>\n",
        "Answer using ONLY the context. Cite as [\"Doc\", \"Section\", \"p. X\"].\n",
        "Not found: \"Not specified in the document.\"\n",
        "Unanswerable: \"This question cannot be answered based on the provided documents.\"</s>\n",
        "<|user|>\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}</s>\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "OUT_OF_SCOPE = [\n",
        "    r\"(?i)\\b(forecast|predict|projection|future|will be|going to)\\b.*\\b(stock|price|revenue|earnings)\\b\",\n",
        "    r\"(?i)\\bstock\\s*price\\s*(forecast|prediction|for|in)\\s*\\d{4}\\b\",\n",
        "    r\"(?i)\\b(2025|2026|2027)\\b\",\n",
        "    r\"(?i)\\bwhat\\s+color\\b\",\n",
        "    r\"(?i)\\b(cfo|ceo|executive).*\\b(2025|current|today|now)\\b\",\n",
        "]\n",
        "\n",
        "def is_out_of_scope(question):\n",
        "    for pattern in OUT_OF_SCOPE:\n",
        "        if re.search(pattern, question):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def clean_answer(text):\n",
        "    text = re.sub(r'<\\|.*?\\|>', '', text)\n",
        "    text = text.replace('</s>', '').replace('<s>', '')\n",
        "    return ' '.join(text.split()).strip()\n",
        "\n",
        "def answer_not_found(answer):\n",
        "    phrases = [\"not specified\", \"not mentioned\", \"not found\", \"no information\", \"does not mention\", \"doesn't mention\", \"not available\", \"cannot be determined\", \"cannot answer\"]\n",
        "    return any(p in answer.lower() for p in phrases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main answer function\n",
        "def answer_question(query):\n",
        "    # Check if out of scope\n",
        "    if is_out_of_scope(query):\n",
        "        return {\"answer\": \"This question cannot be answered based on the provided documents.\", \"sources\": []}\n",
        "    \n",
        "    # Get context\n",
        "    context, sources, chunks = retriever.get_context(query, top_k=3)\n",
        "    if not context.strip():\n",
        "        return {\"answer\": \"Not specified in the document.\", \"sources\": []}\n",
        "    \n",
        "    # Truncate context\n",
        "    tokens = tokenizer.encode(context)\n",
        "    if len(tokens) > 1200:\n",
        "        context = tokenizer.decode(tokens[:1200], skip_special_tokens=True)\n",
        "    \n",
        "    # Generate\n",
        "    prompt = PROMPT_TEMPLATE.format(context=context, question=query)\n",
        "    try:\n",
        "        answer = clean_answer(generate(prompt))\n",
        "        if answer_not_found(answer):\n",
        "            return {\"answer\": \"Not specified in the document.\", \"sources\": []}\n",
        "        return {\"answer\": answer, \"sources\": sources}\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return {\"answer\": \"Error generating response.\", \"sources\": []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation questions\n",
        "EVAL_QUESTIONS = [\n",
        "    {\"question_id\": 1, \"question\": \"What was Apple's total revenue for the fiscal year ended September 28, 2024?\"},\n",
        "    {\"question_id\": 2, \"question\": \"How many shares of common stock were issued and outstanding as of October 18, 2024?\"},\n",
        "    {\"question_id\": 3, \"question\": \"What is the total amount of term debt (current + non-current) reported by Apple as of September 28, 2024?\"},\n",
        "    {\"question_id\": 4, \"question\": \"On what date was Apple's 10-K report for 2024 signed and filed with the SEC?\"},\n",
        "    {\"question_id\": 5, \"question\": \"Does Apple have any unresolved staff comments from the SEC as of this filing? How do you know?\"},\n",
        "    {\"question_id\": 6, \"question\": \"What was Tesla's total revenue for the year ended December 31, 2023?\"},\n",
        "    {\"question_id\": 7, \"question\": \"What percentage of Tesla's total revenue in 2023 came from Automotive Sales (excluding Leasing)?\"},\n",
        "    {\"question_id\": 8, \"question\": \"What is the primary reason Tesla states for being highly dependent on Elon Musk?\"},\n",
        "    {\"question_id\": 9, \"question\": \"What types of vehicles does Tesla currently produce and deliver?\"},\n",
        "    {\"question_id\": 10, \"question\": \"What is the purpose of Tesla's 'lease pass-through fund arrangements'?\"},\n",
        "    {\"question_id\": 11, \"question\": \"What is Tesla's stock price forecast for 2025?\"},\n",
        "    {\"question_id\": 12, \"question\": \"Who is the CFO of Apple as of 2025?\"},\n",
        "    {\"question_id\": 13, \"question\": \"What color is Tesla's headquarters painted?\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "RUNNING EVALUATION\n",
            "============================================================\n",
            "\n",
            "Q1: What was Apple's total revenue for the fiscal year ended September 28, 2024?\n",
            "--------------------------------------------------\n",
            "Answer: Apple's total revenue for the fiscal year ended September 28, 2024, was $391,035.\n",
            "Sources: [\"['Apple 10-K', 'Item 8', 'p. 32']\", \"['Apple 10-K', 'Item 8', 'p. 33']\", \"['Apple 10-K', 'Item 8', 'p. 35']\"]\n",
            "\n",
            "Q2: How many shares of common stock were issued and outstanding as of October 18, 2024?\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2391 > 2048). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: The context of the question mentions that shares of common stock held by executive officers and directors of the Registrant as of October 18, 2024 hav...\n",
            "Sources: [\"['Apple 10-K', 'p. 2']\", \"['Tesla 10-K', 'p. 2']\", \"['Apple 10-K', 'Item 5', 'p. 22']\"]\n",
            "\n",
            "Q3: What is the total amount of term debt (current + non-current) reported by Apple as of September 28, 2024?\n",
            "--------------------------------------------------\n",
            "Answer: The total amount of term debt (current + non-current) reported by Apple as of September 28, 2024 is $131,638.\n",
            "Sources: [\"['Apple 10-K', 'Item 8', 'p. 34']\", \"['Apple 10-K', 'Item 8', 'p. 33']\", \"['Apple 10-K', 'Item 8', 'p. 36']\"]\n",
            "\n",
            "Q4: On what date was Apple's 10-K report for 2024 signed and filed with the SEC?\n",
            "--------------------------------------------------\n",
            "Answer: The question asks about the date when Apple's 10-K report for 2024 was signed and filed with the SEC. The answer is November 1, 2024.\n",
            "Sources: [\"['Apple 10-K', 'Item 8', 'p. 60']\", \"['Apple 10-K', 'Item 8', 'p. 118']\", \"['Apple 10-K', 'Item 8', 'p. 115']\"]\n",
            "\n",
            "Q5: Does Apple have any unresolved staff comments from the SEC as of this filing? How do you know?\n",
            "--------------------------------------------------\n",
            "Answer: Unanswerable: \"This question cannot be answered based on the provided documents.\"\n",
            "Sources: [\"['Apple 10-K', 'Item 1', 'p. 3']\", \"['Apple 10-K', 'Item 8', 'p. 110']\", \"['Apple 10-K', 'Item 1', 'p. 8']\"]\n",
            "\n",
            "Q6: What was Tesla's total revenue for the year ended December 31, 2023?\n",
            "--------------------------------------------------\n",
            "Answer: Tesla's total revenue for the year ended December 31, 2023, was $96,773.\n",
            "Sources: [\"['Tesla 10-K', 'Item 8', 'p. 51']\", \"['Tesla 10-K', 'Item 8', 'p. 52']\", \"['Tesla 10-K', 'Item 8', 'p. 54']\"]\n",
            "\n",
            "Q7: What percentage of Tesla's total revenue in 2023 came from Automotive Sales (excluding Leasing)?\n",
            "--------------------------------------------------\n",
            "Answer: Unanswerable: \"This question cannot be answered based on the provided documents.\"\n",
            "Sources: [\"['Tesla 10-K', 'Item 8', 'p. 51']\", \"['Tesla 10-K', 'Item 1', 'p. 40']\", \"['Tesla 10-K', 'Item 1', 'p. 41']\"]\n",
            "\n",
            "Q8: What is the primary reason Tesla states for being highly dependent on Elon Musk?\n",
            "--------------------------------------------------\n",
            "Answer: Tesla states that Elon Musk is highly dependent on the services of Tesla and our Chief Executive Officer, as he currently serves as Chief Executive Of...\n",
            "Sources: [\"['Tesla 10-K', 'Item 1', 'p. 22']\", \"['Tesla 10-K', 'Item 1', 'p. 21']\", \"['Tesla 10-K', 'Item 1', 'p. 29']\"]\n",
            "\n",
            "Q9: What types of vehicles does Tesla currently produce and deliver?\n",
            "--------------------------------------------------\n",
            "Answer: Tesla currently produces and delivers four-door full-size sedans and mid-size SUVs with seating for up to seven adults, as well as a commercial electr...\n",
            "Sources: [\"['Tesla 10-K', 'Item 1', 'p. 5']\", \"['Tesla 10-K', 'Item 1', 'p. 35']\", \"['Tesla 10-K', 'Item 1', 'p. 34']\"]\n",
            "\n",
            "Q10: What is the purpose of Tesla's 'lease pass-through fund arrangements'?\n",
            "--------------------------------------------------\n",
            "Answer: Tesla's 'lease pass-through fund arrangements' are financial arrangements where Tesla provides financial support to customers who lease its vehicles. ...\n",
            "Sources: [\"['Tesla 10-K', 'Item 1', 'p. 9']\", \"['Tesla 10-K', 'Item 8', 'p. 89']\", \"['Tesla 10-K', 'Item 8', 'p. 59']\"]\n",
            "\n",
            "Q11: What is Tesla's stock price forecast for 2025?\n",
            "--------------------------------------------------\n",
            "Answer: This question cannot be answered based on the provided documents.\n",
            "Sources: []\n",
            "\n",
            "Q12: Who is the CFO of Apple as of 2025?\n",
            "--------------------------------------------------\n",
            "Answer: This question cannot be answered based on the provided documents.\n",
            "Sources: []\n",
            "\n",
            "Q13: What color is Tesla's headquarters painted?\n",
            "--------------------------------------------------\n",
            "Answer: This question cannot be answered based on the provided documents.\n",
            "Sources: []\n",
            "\n",
            "============================================================\n",
            "DONE\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation\n",
        "print(\"=\" * 60)\n",
        "print(\"RUNNING EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "results = []\n",
        "for q in EVAL_QUESTIONS:\n",
        "    qid = q[\"question_id\"]\n",
        "    question = q[\"question\"]\n",
        "    \n",
        "    print(f\"\\nQ{qid}: {question}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    response = answer_question(question)\n",
        "    results.append({\"question_id\": qid, \"answer\": response[\"answer\"], \"sources\": response[\"sources\"]})\n",
        "    \n",
        "    ans = response[\"answer\"]\n",
        "    print(f\"Answer: {ans[:150]}...\" if len(ans) > 150 else f\"Answer: {ans}\")\n",
        "    print(f\"Sources: {response['sources']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DONE\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved to: /content/evaluation_results.json\n",
            "\n",
            "Final Results:\n",
            "[\n",
            "  {\n",
            "    \"question_id\": 1,\n",
            "    \"answer\": \"Apple's total revenue for the fiscal year ended September 28, 2024, was $391,035.\",\n",
            "    \"sources\": [\n",
            "      \"['Apple 10-K', 'Item 8', 'p. 32']\",\n",
            "      \"['Apple 10-K', 'Item 8', 'p. 33']\",\n",
            "      \"['Apple 10-K', 'Item 8', 'p. 35']\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 2,\n",
            "    \"answer\": \"The context of the question mentions that shares of common stock held by executive officers and directors of the Registrant as of October 18, 2024 have been excluded because such persons may be deemed to be affiliates. This determination of affiliate status is not necessarily a conclusive determination for other purposes. The context also mentions that shares of common stock were issued and outstanding as of October 18, 2024.\",\n",
            "    \"sources\": [\n",
            "      \"['Apple 10-K', 'p. 2']\",\n",
            "      \"['Tesla 10-K', 'p. 2']\",\n",
            "      \"['Apple 10-K', 'Item 5', 'p. 22']\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 3,\n",
            "    \"answer\": \"The total amount of term debt (current + non-current) reported by Apple as of September 28, 2024 is $131,638.\",\n",
            "    \"sources\": [\n",
            "      \"['Apple 10-K', 'Item 8', 'p. 34']\",\n",
            "      \"['Apple 10-K', 'Item 8', 'p. 33']\",\n",
            "      \"['Apple 10-K', 'Item 8', 'p. 36']\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 4,\n",
            "    \"answer\": \"The question asks about the date when Apple's 10-K report for 2024 was signed and filed with the SEC. The answer is November 1, 2024.\",\n",
            "    \"sources\": [\n",
            "      \"['Apple 10-K', 'Item 8', 'p. 60']\",\n",
            "      \"['Apple 10-K', 'Item 8', 'p. 118']\",\n",
            "      \"['Apple 10-K', 'Item 8', 'p. 115']\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 5,\n",
            "    \"answer\": \"Unanswerable: \\\"This question cannot be answered based on the provided documents.\\\"\",\n",
            "    \"sources\": [\n",
            "      \"['Apple 10-K', 'Item 1', 'p. 3']\",\n",
            "      \"['Apple 10-K', 'Item 8', 'p. 110']\",\n",
            "      \"['Apple 10-K', 'Item 1', 'p. 8']\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 6,\n",
            "    \"answer\": \"Tesla's total revenue for the year ended December 31, 2023, was $96,773.\",\n",
            "    \"sources\": [\n",
            "      \"['Tesla 10-K', 'Item 8', 'p. 51']\",\n",
            "      \"['Tesla 10-K', 'Item 8', 'p. 52']\",\n",
            "      \"['Tesla 10-K', 'Item 8', 'p. 54']\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 7,\n",
            "    \"answer\": \"Unanswerable: \\\"This question cannot be answered based on the provided documents.\\\"\",\n",
            "    \"sources\": [\n",
            "      \"['Tesla 10-K', 'Item 8', 'p. 51']\",\n",
            "      \"['Tesla 10-K', 'Item 1', 'p. 40']\",\n",
            "      \"['Tesla 10-K', 'Item 1', 'p. 41']\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 8,\n",
            "    \"answer\": \"Tesla states that Elon Musk is highly dependent on the services of Tesla and our Chief Executive Officer, as he currently serves as Chief Executive Officer and Chief Technical Officer of Space Exploration Technologies Corp., a developer and manufacturer of space launch vehicles, Chairman and Chief Technical Officer of X Corp., and is involved in other emerging technology ventures. This dependence is due to the fact that Tesla relies heavily on Musk's expertise and attention to detail, as well as his ability to devote significant time and attention to Tesla.\",\n",
            "    \"sources\": [\n",
            "      \"['Tesla 10-K', 'Item 1', 'p. 22']\",\n",
            "      \"['Tesla 10-K', 'Item 1', 'p. 21']\",\n",
            "      \"['Tesla 10-K', 'Item 1', 'p. 29']\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 9,\n",
            "    \"answer\": \"Tesla currently produces and delivers four-door full-size sedans and mid-size SUVs with seating for up to seven adults, as well as a commercial electric vehicle, the Tesla Semi. In 2022, Tesla also began early production and deliveries of a commercial electric vehicle, the Tesla Semi.\",\n",
            "    \"sources\": [\n",
            "      \"['Tesla 10-K', 'Item 1', 'p. 5']\",\n",
            "      \"['Tesla 10-K', 'Item 1', 'p. 35']\",\n",
            "      \"['Tesla 10-K', 'Item 1', 'p. 34']\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 10,\n",
            "    \"answer\": \"Tesla's 'lease pass-through fund arrangements' are financial arrangements where Tesla provides financial support to customers who lease its vehicles. These arrangements commit Tesla to providing performance guarantees that commit the company to meeting or exceeding the minimum energy generation or performance requirements specified in the lease contract. The financial services offered by these arrangements include purchase financing and leases, which are used to finance Tesla's solar energy systems and energy storage contracts. Tesla may also offer leasing and/or loan financing arrangements for its vehicles in certain jurisdictions in North America, Europe, and Asia, where it has provided resale value guarantees or buyback guarantees that may obligate it to cover a resale loss up to a certain limit or repurchase the subject vehicles at pre-determined values.\",\n",
            "    \"sources\": [\n",
            "      \"['Tesla 10-K', 'Item 1', 'p. 9']\",\n",
            "      \"['Tesla 10-K', 'Item 8', 'p. 89']\",\n",
            "      \"['Tesla 10-K', 'Item 8', 'p. 59']\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 11,\n",
            "    \"answer\": \"This question cannot be answered based on the provided documents.\",\n",
            "    \"sources\": []\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 12,\n",
            "    \"answer\": \"This question cannot be answered based on the provided documents.\",\n",
            "    \"sources\": []\n",
            "  },\n",
            "  {\n",
            "    \"question_id\": 13,\n",
            "    \"answer\": \"This question cannot be answered based on the provided documents.\",\n",
            "    \"sources\": []\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Save and display results\n",
        "output_file = os.path.join(DATA_DIR, \"evaluation_results.json\")\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print(f\"Saved to: {output_file}\")\n",
        "\n",
        "print(\"\\nFinal Results:\")\n",
        "print(json.dumps(results, indent=2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "RAG",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
